{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train mô hình Logistic Regression"
   ],
   "id": "c00f63a3901833f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import các thư viện",
   "id": "79f78fe0c2033232"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:04.958593Z",
     "start_time": "2025-05-14T14:06:04.942801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ],
   "id": "afe89e95f045f4f6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:04.990350Z",
     "start_time": "2025-05-14T14:06:04.974600Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Load hyperparameters từ JSON",
   "id": "71f6235742cb9d6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:05.006016Z",
     "start_time": "2025-05-14T14:06:04.990350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths đến 3 file JSON\n",
    "param_files = {\n",
    "    'LabelEncoder_noSubject':   '../hyperparameter_tuning/Best_Hyperparameter/BestParameter_LogisticRegression_full_features.json',\n",
    "    'PCA':    '../hyperparameter_tuning/Best_Hyperparameter/BestParameter_LogisticRegression_PCA.json',\n",
    "    'reduced_Correlation':'../hyperparameter_tuning/Best_Hyperparameter/BestParameter_LogisticRegression_reduced_features.json',\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "for name, path in param_files.items():\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        best_params[name] = json.load(f)\n"
   ],
   "id": "7126ae45bf4a7402",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Load dữ liệu train/test",
   "id": "50349b15dd457117"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:06:05.940028Z",
     "start_time": "2025-05-14T14:06:05.006016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_sets = {}\n",
    "for name in ['LabelEncoder_noSubject', 'PCA', 'reduced_Correlation']:\n",
    "    df_train = pd.read_csv(f'../../data/processed/train_{name}.csv')\n",
    "    df_test  = pd.read_csv(f'../../data/processed/test_{name}.csv')\n",
    "\n",
    "    try:\n",
    "        X_train = df_train.drop(['Activity', 'Activity_code'], axis=1)\n",
    "        X_test  = df_test.drop(['Activity', 'Activity_code'], axis=1)\n",
    "    except KeyError:\n",
    "        X_train = df_train.drop('Activity_code', axis=1)\n",
    "        X_test  = df_test.drop('Activity_code', axis=1)\n",
    "        \n",
    "    y_train = df_train['Activity_code']\n",
    "    y_test  = df_test['Activity_code']\n",
    "\n",
    "    data_sets[name] = (X_train, y_train, X_test, y_test)\n"
   ],
   "id": "10ff8f16ee667f53",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Huấn luyện và lưu model",
   "id": "56ecadbc2af42ab1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:14:17.613479Z",
     "start_time": "2025-05-14T14:13:40.426010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name_model = ['full', 'pca', 'reduced']\n",
    "for (name, params), model_name in zip(best_params.items(), name_model):\n",
    "    X_train, y_train, _, _ = data_sets[name]\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=params['C'],\n",
    "        penalty=params['penalty'],\n",
    "        solver=params['solver'],\n",
    "        max_iter=params['max_iter']\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Lưu model\n",
    "    joblib.dump(model, f'../../models/logreg_{model_name}.joblib')\n",
    "    print(f\"› Saved logreg_{model_name}.joblib\")\n"
   ],
   "id": "16c6e486a17cb2b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "› Saved logreg_full.joblib\n",
      "› Saved logreg_pca.joblib\n",
      "› Saved logreg_reduced.joblib\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Đánh giá trên tập test",
   "id": "d52d38973e303c3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:35:32.522357Z",
     "start_time": "2025-05-14T14:35:32.475552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for nameModel, name in zip(name_model, ['LabelEncoder_noSubject', 'PCA', 'reduced_Correlation']):\n",
    "    _, _, X_test, y_test = data_sets[name]\n",
    "    model = joblib.load(f'../../models/logreg_{nameModel}.joblib')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"--- Results on {nameModel} features ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "id": "21eaa951f6399971",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results on full features ---\n",
      "Accuracy: 0.9616559212758737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       0.97      0.87      0.92       491\n",
      "           2       0.90      0.98      0.93       532\n",
      "           3       0.95      1.00      0.97       496\n",
      "           4       1.00      0.97      0.98       420\n",
      "           5       0.97      0.95      0.96       471\n",
      "\n",
      "    accuracy                           0.96      2947\n",
      "   macro avg       0.96      0.96      0.96      2947\n",
      "weighted avg       0.96      0.96      0.96      2947\n",
      "\n",
      "--- Results on pca features ---\n",
      "Accuracy: 0.9317950458092976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       537\n",
      "           1       0.92      0.86      0.89       491\n",
      "           2       0.88      0.93      0.91       532\n",
      "           3       0.93      0.98      0.95       496\n",
      "           4       0.94      0.90      0.92       420\n",
      "           5       0.91      0.91      0.91       471\n",
      "\n",
      "    accuracy                           0.93      2947\n",
      "   macro avg       0.93      0.93      0.93      2947\n",
      "weighted avg       0.93      0.93      0.93      2947\n",
      "\n",
      "--- Results on reduced features ---\n",
      "Accuracy: 0.9504580929759077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       0.94      0.87      0.90       491\n",
      "           2       0.89      0.94      0.91       532\n",
      "           3       0.94      0.98      0.96       496\n",
      "           4       0.99      0.96      0.97       420\n",
      "           5       0.96      0.95      0.96       471\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.95      0.95      0.95      2947\n",
      "weighted avg       0.95      0.95      0.95      2947\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Tính thời gian inference trên 1 mẫu (Latency)",
   "id": "a716d18caf7aaa09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:12:01.570593Z",
     "start_time": "2025-05-14T15:11:29.907182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ─── Cell: Latency Measurement Function ───────────────────────────────────────\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def measure_latency_highres_ms(model, X, warmup=10, repeats=1):\n",
    "    \"\"\"\n",
    "    Đo latency per–sample với độ phân giải cao, trả về kết quả bằng ms.\n",
    "\n",
    "    Thực hiện `warmup` lần predict đầu để làm nóng (cache) model.\n",
    "    Với mỗi mẫu, lặp `repeats` lần và lấy trung bình để giảm nhiễu.\n",
    "    \"\"\"\n",
    "    # Giữ X ở dạng DataFrame để tránh warning về feature_names\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X_df = pd.DataFrame(X, columns=model.feature_names_in_)\n",
    "    else:\n",
    "        X_df = X.copy()\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(warmup):\n",
    "        _ = model.predict(X_df.iloc[[0]])\n",
    "\n",
    "    times_ns = []\n",
    "    for i in range(len(X_df)):\n",
    "        sample = X_df.iloc[[i]]\n",
    "        total_ns = 0\n",
    "        for _ in range(repeats):\n",
    "            t0 = time.perf_counter_ns()\n",
    "            _ = model.predict(sample)\n",
    "            total_ns += time.perf_counter_ns() - t0\n",
    "        times_ns.append(total_ns / repeats)\n",
    "\n",
    "    times_ns = np.array(times_ns)\n",
    "    # chuyển nanô-giây -> mili-giây\n",
    "    times_ms = times_ns / 1e6\n",
    "\n",
    "    return {\n",
    "        'mean_ms': times_ms.mean(),\n",
    "        'p50_ms':  np.percentile(times_ms, 50),\n",
    "        'p95_ms':  np.percentile(times_ms, 95)\n",
    "    }\n",
    "# ─── Cell: Gọi đo latency cho từng model trên mỗi feature set ────────────────\n",
    "for data_name, model_name in zip(['LabelEncoder_noSubject', 'PCA', 'reduced_Correlation'], ['full', 'pca', 'reduced']):\n",
    "    # load model nếu cần, hoặc dùng `model` vừa train\n",
    "    model = joblib.load(f'../../models/logreg_{model_name}.joblib')\n",
    "    X_test = data_sets[data_name][2]  # (X_train, y_train, X_test, y_test)\n",
    "\n",
    "    lat_ms = measure_latency_highres_ms(model, X_test, warmup=10, repeats=3)\n",
    "    print(f\"--- Latency of LogisticRegression on {model_name} features ---\")\n",
    "    print(f\"Mean   : {lat_ms['mean_ms']:.3f} ms\")\n",
    "    print(f\"P50    : {lat_ms['p50_ms']:.3f} ms\")\n",
    "    print(f\"P95    : {lat_ms['p95_ms']:.3f} ms\")\n"
   ],
   "id": "bb07db3e8d569552",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Latency of LogisticRegression on full features ---\n",
      "Mean   : 1.917 ms\n",
      "P50    : 1.872 ms\n",
      "P95    : 2.330 ms\n",
      "--- Latency of LogisticRegression on pca features ---\n",
      "Mean   : 0.650 ms\n",
      "P50    : 0.627 ms\n",
      "P95    : 0.772 ms\n",
      "--- Latency of LogisticRegression on reduced features ---\n",
      "Mean   : 0.936 ms\n",
      "P50    : 0.903 ms\n",
      "P95    : 1.118 ms\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2cc2f5e9898d9a25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
